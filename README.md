## üìö Mapeamento Completo de T√≥picos para Aprender PySpark

### **1. Estruturas Fundamentais da Linguagem (Python B√°sico)**
*(Notebook : `01_Base_Python_Estruturas`)*

* **Vari√°veis** (Guardar valores)
* **Listas** (V√°rios valores)
* **Dicion√°rio** (Estrutura `Chave: Valor`, similar a JSON)
* **Condi√ß√£o** (`if` para tomada de decis√£o)
* **Loop** (`for` para repeti√ß√£o de a√ß√µes)
* **Fun√ß√£o** (`def` para criar c√≥digo reutiliz√°vel)

### **2. Tarefas e Aplica√ß√µes Pr√°ticas com Dados**
*(Notebook : `02_Manipulacao_e_IO_Basico`)*

* **Manipula√ß√£o B√°sica** (Tarefas que envolvem Listas e Dicion√°rios)
* **Tratar Dados** (L√≥gica de limpeza e valida√ß√£o de informa√ß√µes)
* **Fun√ß√µes** (O ato de **usar** as fun√ß√µes criadas)
* **Ler/Escrever Arquivos** (Opera√ß√µes de I/O para carregar e salvar dados)
* **Pandas** (Uso da biblioteca para an√°lise tabular)
* **ETL (Extrair, Transformar, Carregar)** (Processo de engenharia de dados que usa todas as ferramentas)

### **3. Estruturas de Dados do PySpark**
*(Notebook : `03_DataFrames_e_Schema`)*

* **DataFrame:** A estrutura principal (tabela distribu√≠da) do PySpark.
* **Schema:** O dicion√°rio que define o nome e o tipo de dados exato de cada coluna.
* **RDD:** A estrutura de dados original do Spark.
* **Column:** O objeto que representa uma coluna individual dentro de um DataFrame.

### **4. Transforma√ß√µes e A√ß√µes (Processamento Distribu√≠do)**
*(Notebook : `04_Transformacoes_e_SQL_Spark`)*

* **Sele√ß√£o e Proje√ß√£o:** Comandos (`select`, `withColumn`) para adicionar, remover ou renomear colunas.
* **Filtragem:** Comandos (`filter`, `where`) para selecionar linhas com base em condi√ß√µes.
* **Agrega√ß√£o e Agrupamento:** Comandos (`groupBy`, `agg`) para calcular m√©tricas.
* **Jun√ß√µes (`join`):** Comandos para combinar dois ou mais DataFrames.

### **5. Otimiza√ß√£o e Escalabilidade**
*(Notebook : `05_Otimizacao_e_Fluxo_ETL`)*

* **Particionamento:** Como o Spark divide os dados para processamento paralelo eficiente.
* **Caching:** Comandos (`cache`, `persist`) para armazenar DataFrames frequentemente usados na mem√≥ria.
* **Fun√ß√µes Definidas pelo Usu√°rio (UDFs):** Fun√ß√µes personalizadas em Python que o Spark pode executar.
* **Modos de Execu√ß√£o (Lazy Evaluation):** O conceito de que o Spark s√≥ executa o c√≥digo quando um comando de "a√ß√£o" (como `show()`) √© chamado.
